\section{Tumour deformation modelling}
\label{chapterlabel3}

Tract orientation atlases represent the expected orientation and location of a tract in typical healthy subjects.
In the previous chapter we asserted that, for subjects with little structural divergence from the norm, linear registration is sufficient for aligning the atlas and target data.
However, in cases with large mass-effect, affine registration becomes clearly inadequate, as the distances between expected and actual location of brain structures is simply too great.
In order to correct for displacement of white matter tracts due to space-occupying lesions, the atlas will need to be deformed more dramatically before comparing with the native \gls{fod} map.

Anatomical non-correspondence between subject and template images caused by space-occupying lesions poses a substantial challenge to the use of atlas-based white matter segmentation methods in clinical subjects.
While nonlinear deformation tools can produce accurate registration in clinical images, they require usually manual adjustment of many input and regularisation parameters on a case by case basis, and a robust automation of this process is not available to best knowledge.
More significantly, in the case of registration between a normative template and a scan with a brain tumour, a fundamental assumption of many registration algorithms, that of topological equivalence between the two images, does not hold.\autocite{Zacharaki2009}
The core of the problem is that one image -- the template -- depicts the anatomy of an average, healthy brain, and the other that of a diseased brain harbouring a tumour, presenting two potential scenarios.
Either the lesion exists \textit{in addition} to all the structures and tissue expected of a healthy brain, which have been displaced or compressed to accommodate it, or it has \textit{replaced} brain landmarks or rendered them otherwise unrecognisable through the effects of odoema or differing MR properties between tumour and healthy brain tissue.
In either case, a non-linear registration algorithm is tasked with finding a mapping between two images with different sets of anatomical landmarks, with finding anatomical correspondence between tissue in one image which is nonexistant in the other.
The result of this violation of the topological equivalence assumption is often ridiculously contorted images, and particularly in the peritumoural zone, which is rather problematic for neurosurgical applications.

Deformable registration alone is thus largely insufficient for handling the anatomical mismatch problem. \autocite{Elazab2018, Visser2020}
It has long been proposed that an acceptable registration between atlas and tumour data can only be obtained with an additional step of artificially implanting or modelling a representation of the tumour in the atlas.\autocite{Cabezas2011,Mang2020}
This can be in the form of a seeded atlas deformation,\autocite{Dawant2002} in which a small seed is placed in the atlas before deformable registration, acting as a region of tissue which can be warped to match the full tumour in patient space.
Alternatively, the seed can be artificially ``grown" using a biophysical or mathematical model of tumour proliferation to simulate deformation, with optional further nonlinear registration of the deformed atlas to the patient image.\autocite{Cuadra2004, Zacharaki2009}
Many proposed tumour deformation models aim to achieve highly accurate modelling of tumour growth dynamics and the effects on surrounding tissues, by taking into account elastic tissue properties and microscopic tumour growth modelling (see \textcite{Elazab2018} for a comprehensive review).
Generally models will consider one or a coupling\autocite{Clatz2005,Hogea2007,Prastawa2009} of tumour cellular proliferation and infiltration into surrounding tissues using a reaction diffusion or similar framework,\autocite{Tunc2021,Scheufele2019b,Elaff2018}
or the biomechanical forces acting between tissues.\autocite{Mohamed2006,Hogea2007a,Zacharaki2009}
The resulting algorithms are often mathematically complex and implementated using finite element methods,\autocite{Elazab2018} require optimisation of tumour parameters through problem inversion or by other means \autocite{Mohamed2006, Zacharaki2009, Mang2020} and take anywhere between 1 and 36 hours to run, even on high performance computing setups.\autocite{Zacharaki2009,Bauer2012,Bauer2013,Mang2012}
This is entirely reasonable for studies in which accuracy is a far greater priority than speed.
Typical applications of tumour deformation modelling include intra-patient longitudinal studies of tumour growth, and inter-patient registration and spatial normalisation for atlas-based segmentation or statistical analysis across patient populations (see \textcite{Bauer2013} and \textcite{Cabezas2011} for overviews).
Given the time constraints of intraoperative imaging and the practical constraints of the computing capacity which can reasonably be assumed to be available in a clinical setup, the aim for this project was to achieve an estimate of tract displacement with low computational complexity.

The tract orientation atlas described in the previous chapter provides a degree of spatial tolerance that alleviates the need for voxel-perfect registration and deformation, allowing the implementation of a minimal deformation algorithm.
The idea is to obtain a deformation model which is simple enough to compute using few temporal and computational resources, and use it in combination with affine registration, as before, to achieve spatial alignment between atlas and patient space.
To this end we will interest ourselves solely in the macroscopic spatial effects of tumour growth: what effect does the presence of a tumour have on the physical location a given volume unit of tissue?
Of course, this question cannot be fully answered without considering the complicated factors described above, such as whether a tumour is encapsulated or infiltrating.
Nevertheless, as all models are wrong, and some are useful, the utility of our model will be measured by it's ease of computation and accurate capturing of tract displacement.
Whether performance in the latter criteria is satisfactory will be measured through the resulting improvement in tract mapping as compared with patient-native methods such as streamline tractography (see Section \ref{sec:btcd}).
We will consider a radial model of tumour deformation, assuming the tumour has expanded outwards from a central seed, and that surrounding tissue is displaced along the same radial directions.
\textcite{Cuadra2004} similarly used a radial expansion assumption, but for modelling the interior tumour region (rather than outside the tumour), while an optical flow algorithm was implemented for image matching outside the tumour.

\subsection{Development of a radial deformation model}

We begin with a radial deformation model described by Nowinski and Belov \citep{Nowinski2005}.
Their motivation was remarkably similar: the rapid deformation of a morphological brain atlas to aid the interpretation of brain anatomies affected by tumour mass effect.
The required model inputs are the segmentations of the tumour and brain volumes.
We define the direction $\mathbf{\hat{e}}$, which is the unit vector along the line connecting a point anywhere within the brain $P(x,y,z)$ to the tumour centre of mass, $S$.
This is the direction along which we assume the tissue at that point to be shifted by the tumour: radially outward from the tumour centre.
Along $\mathbf{\hat{e}}$ we also define $D_p$ as the distance  $\|\overrightarrow{SP}\|$, $D_b$ as the distance from $S$ to the brain surface and $D_t$ as the distance from $S$ to the tumour surface (Fig. \ref{fig:virtue}).

\begin{figure}[htp]
  \centering
  \includegraphics{virtue_vars.pdf}
  \caption{Graphical schema of the variables defined in the radial deformation model}
  \label{fig:virtue}
\end{figure}

Then for a point in the original image $P = (x,y,z)$ the transformed location in the deformed image $P' = (x',y',z')$ is

\begin{align}\label{eq:forwardP}
  P' = f(P) = P + \mathbf{\hat{e}}kD_ts.
\end{align}

The amount of displacement $\Delta P = kD_ts$ is thus determined by $D_t$, a scale factor $0<s \leq 1$ and a displacement factor $k$.
In \textcite{Nowinski2005}, $k$ is a linear function of $D_p$: $k = 1-\frac{D_p}{D_b}$. \footnote[2]{In the original \textcite{Nowinski2005} article, the deformation is described in reverse, as a shrinking model, and the variables there look a little different. They are consistent with the formulation used here, which has been chosen for ease of conceptualisation. Note that both forward and reverse models are required for different types of image transformation, and will be derived later.}
This can be conceptualised as a displacement force radiating from the centre of the tumour and decaying linearly with distance, reaching 0 only at the brain boundary.
However, initial experimentations with this model revealed that such a linearly decaying force doesn't do well at capturing the displacement fields observed in real tumour cases.
The elasticity and compressibility of brain tissue means that the radial force is absorbed by surrounding tissue more rapidly than the linear function suggests.
Even with very large tumours, it is common for parts of the brain some distance from the tumour surface to experience no displacement at all, suggesting a  more rapidly decaying function would be a more appropriate choice for $k$.

An exponentially decaying function captures this well, while remaining easily computable, close-form and invertible.
We begin with a function in the form $k \propto e^{-\lambda \frac{D_p}{D_t}}$.
There are two boundary conditions: points on the brain surface should not be displaced ($k(D_p = D_b) = 0$) and points at the centre of the tumour should be displaced by exactly $D_t$ ($k(D_p = 0) = 1$).
Note that the latter boundary condition is an assumption reflecting a fully encapsulated tumour, where no normal tumour remains inside the final tumour boundary after displacement.
Solving for these boundary conditions gives us a normalisation constant:

\begin{align*}
  k &= a e^{-\lambda x} + c &\text{ where } x = D_p / D_b \\
  k(x=0)=1 \longrightarrow 1 &= a e^{-0} + c = a + c \\
  k(x=1)=0 \longrightarrow 0 &= a e{^-\lambda} + c \\
  -c &= (1-c) e^{-\lambda} \\
  c &= \frac{e^{-\lambda}}{e^{-\lambda} - 1}
\end{align*}

giving

\begin{align}\label{eq:forwardk}
  k(P) = (1-c)e^{-\lambda \frac{D_p}{D_b}} +c.
\end{align}

Equations (\ref{eq:forwardP}) and (\ref{eq:forwardk}) describe the deformation field in forward warp convention, where a point in the original image is mapped to a position in the transformed image.
Forward warping works well for continuous valued data, for example streamlines.
However, for discreet data such as pixels (or voxels), forward warping brings the problem of ``holes", when a mapped location in the destination image falls between coordinates on the discreet voxel grid, and the original sample value has to be distributed among the neighbouring grid points.
Thus it is usually preferable, if the warping function is invertible, to determine for each grid point in the transformed image, the corresponding continuous-valued point in the source image from which the appropriate value can be interpolated from the surrounding grid points. \note{does this make sense??}
Reverse warp convention is used by most \note{??} medical image manipulation packages to deform (and resample) a gridded image.
Thus we need to obtain the inverse mapping $P = f^{-1}(P')$ by solving equation (\ref{eq:forwardP}) for $P$:

\begin{align}
  P = P' - \mathbf{\hat{e}}(D_t c - \frac{D_b}{\lambda}\mathcal{W}_0(\frac{-\lambda D_t (1-c) e^{-\lambda(D_{p'}-D_tc)/D_b}}{D_b}))
\end{align}

where $\mathcal{W}_0(y)$ is the principal branch of the lambert $\mathcal{W}$ function, defined as the inverse function of $ y(x) = xe^x $ for $x,y \in \mathbb{R}$. \note{derive this ?in appendix??}

The inverse function for the linear model is (as formulated in \textcite{Nowinski2005}):

\begin{align}
  P = P' - \mathbf{\hat{e}}(1-\frac{D_{P'}-D_t}{D_b-D_t})D_ts
\end{align}

The appropriate value for the decay parameter $\lambda$ will depend on the specific lesion being modelled. For example, smaller lesions (20-30mm diameter) typically displace tissue only in their immediate surroundings, with distant tissue remaining virtually unmoved. In such cases, a higher value of $\lambda$ ($\geq 3$), indicating stronger decay of deformation, would be appropriate (Figure \ref{fig:virtue}).
In any case, in order to keep the transforms well behaved, we need to maintain the condition that every point $P$ in the source image that is within the tumour boundary ends up strictly outside the tumour in the eventual deformed image.
In other words,

\begin{equation}\label{eq:lambdabound}
  k(P) \geq 1 - \frac{D_P}{D_t}
\end{equation}

must hold for all $P$.

Given that the gradient of $k$ is strictly decreasing and $g(D_P) = 1 - \frac{D_P}{D_t}$ is linear, it is sufficient to set
\begin{align*}
  \frac{d}{dP}\bigg\rvert_{D_P=0}k(D_P) &= \frac{d}{dP}\bigg\rvert_{D_P=0}g(D_P) &\text{ where } \frac{dk}{dP} &= -\frac{\lambda}{D_b}(1-c)e^{-D_p/D_b} &\text{ and } \frac{dg}{dP} &= -\frac{1}{D_t}
\end{align*}

We solve for $\lambda$:

\begin{align*}
  -\frac{\lambda_{max}}{D_b}(1-c) &= -\frac{1}{D_t} \\
  \lambda_{max} &= \frac{D_b}{D_t (1-c)}
\end{align*}

This value can be determined iteratively, or analytically with the expression

\begin{equation}
  \lambda_{max} = \mathcal{W}_0(-\frac{D_b}{D_t}e^{-D_b/D_t})+\frac{D_b}{D_t}
\end{equation}

Thus for strictly non-infiltrating lesions, we set $\lambda \leq \lambda_{max}$ to satisfy equation (\ref{eq:lambdabound}), where $\lambda_{max}$ is used as the default value if none is specified (referred to as ``adaptive $\lambda$").
Note that $\lambda_{max}$ varies throughout the brain, as it depends on the relative distances to brain and tumour surfaces for each specific $P$.

The tumour deformation model is implemented in Python, and full execution takes on average 1 min for a 208 x 256 x 256 voxel image.
If lookup tables for $ D_t$ and $D_b$ are precomputed and saved, then subsequent executions of the model (e.g. with different values for $\lambda$ and $s$, as appropriate for a given tumour) take less than 10 seconds, as long as the tumour and brain segmentations remain unchanged.

\note{Maybe also some speculative stuff about infiltration}
